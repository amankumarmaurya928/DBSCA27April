{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d2eaa0-2ef8-4323-8605-f6e5a99759ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clustering is a popular technique for segmenting data. The primary options for clustering in R are kmeans for K-means, pam\\n   in cluster for K-medoids and hclust for hierarchical clustering.\\n   It is an iterative algorithm that divides the unlabeled dataset into k different clusters in such a way that each dataset\\n   belongs only one group that has similar properties.\\n   Types of Clustering\\n1. Centroid-based Clustering.\\n2. Density-based Clustering.\\n3. Distribution-based Clustering.\\n4. Hierarchical Clustering.\\n5. Centroid-based Clustering. In this type of clustering, clusters are represented by a central entity, which may or may not\\n   be a part of the given data set.\\n6. Distribution-based Clustering. \\n7. Density-based Clustering.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''Clustering is a popular technique for segmenting data. The primary options for clustering in R are kmeans for K-means, pam\n",
    "   in cluster for K-medoids and hclust for hierarchical clustering.\n",
    "   It is an iterative algorithm that divides the unlabeled dataset into k different clusters in such a way that each dataset\n",
    "   belongs only one group that has similar properties.\n",
    "   Types of Clustering\n",
    "1. Centroid-based Clustering.\n",
    "2. Density-based Clustering.\n",
    "3. Distribution-based Clustering.\n",
    "4. Hierarchical Clustering.\n",
    "5. Centroid-based Clustering. In this type of clustering, clusters are represented by a central entity, which may or may not\n",
    "   be a part of the given data set.\n",
    "6. Distribution-based Clustering. \n",
    "7. Density-based Clustering.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7904c12d-cc83-4b83-b9eb-a1000249c33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"K-means is a centroid-based clustering algorithm, where we calculate the distance between each data point and a centroid to \\n   assign it to a cluster. The goal is to identify the K number of groups in the dataset.\\n   A cluster refers to a collection of data points aggregated together because of certain similarities. You'll define a target\\n   number k, which refers to the number of centroids you need in the dataset. A centroid is the imaginary or real location\\n   representing the center of the cluster.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''K-means is a centroid-based clustering algorithm, where we calculate the distance between each data point and a centroid to \n",
    "   assign it to a cluster. The goal is to identify the K number of groups in the dataset.\n",
    "   A cluster refers to a collection of data points aggregated together because of certain similarities. You'll define a target\n",
    "   number k, which refers to the number of centroids you need in the dataset. A centroid is the imaginary or real location\n",
    "   representing the center of the cluster.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f6ab0b-5155-4ca2-b5f3-65122fd79266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Advantages of k-means:\\n   Guarantees convergence. Can warm-start the positions of centroids. Easily adapts to new examples. Generalizes to clusters of\\n   different shapes and sizes, such as elliptical clusters.\\n   Limitations of k-means:\\n   The most important limitations of Simple k-means are: The user has to specify k (the number of clusters) in the beginning.\\n   k-means can only handle numerical data. k-means assumes that we deal with spherical clusters and that each cluster has\\n   roughly equal numbers of observations. \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''Advantages of k-means:\n",
    "   Guarantees convergence. Can warm-start the positions of centroids. Easily adapts to new examples. Generalizes to clusters of\n",
    "   different shapes and sizes, such as elliptical clusters.\n",
    "   Limitations of k-means:\n",
    "   The most important limitations of Simple k-means are: The user has to specify k (the number of clusters) in the beginning.\n",
    "   k-means can only handle numerical data. k-means assumes that we deal with spherical clusters and that each cluster has\n",
    "   roughly equal numbers of observations. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448b746d-5d48-4a68-a9b1-4936f92f77fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The silhouette coefficient may provide a more objective means to determine the optimal number of clusters. This is done by\\n   simply calculating the silhouette coefficient over a range of k, & identifying the peak as optimum K.\\n   The optimal number of clusters can be defined as follow:\\n1. Compute clustering algorithm (e.g., k-means clustering) for different values of k.\\n2. For each k, calculate the total within-cluster sum of square (wss).\\n3. Plot the curve of wss according to the number of clusters k.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''The silhouette coefficient may provide a more objective means to determine the optimal number of clusters. This is done by\n",
    "   simply calculating the silhouette coefficient over a range of k, & identifying the peak as optimum K.\n",
    "   The optimal number of clusters can be defined as follow:\n",
    "1. Compute clustering algorithm (e.g., k-means clustering) for different values of k.\n",
    "2. For each k, calculate the total within-cluster sum of square (wss).\n",
    "3. Plot the curve of wss according to the number of clusters k.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d606c9a-9091-471f-809f-0e3ddccd2e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real-life examples include spam detection, sentiment analysis, scorecard prediction of exams, etc. \\n   2) Regression Models – Regression models are used for problems where the output variable is a real value such as a unique \\n   number, dollars, salary, weight or pressure, as example.\\n   Some examples of clustering include document clustering, fraud detection, fake news detection, customer segmentation, etc.\\n   This article lists some exciting and unique clustering projects in machine learning that will help you understand the \\n   real-world applications of clustering.\\n   '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''Real-life examples include spam detection, sentiment analysis, scorecard prediction of exams, etc. \n",
    "   2) Regression Models – Regression models are used for problems where the output variable is a real value such as a unique \n",
    "   number, dollars, salary, weight or pressure, as example.\n",
    "   Some examples of clustering include document clustering, fraud detection, fake news detection, customer segmentation, etc.\n",
    "   This article lists some exciting and unique clustering projects in machine learning that will help you understand the \n",
    "   real-world applications of clustering.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc43a659-cdac-40ca-8037-2981d04d3cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interpreting the meaning of k-means clusters boils down to characterizing the clusters. A Parallel Coordinates Plot allows\\n   us to see how individual data points sit across all variables. By looking at how the values for each variable compare\\n   across clusters, we can get a sense of what each cluster represents.\\n   The output of kmeans is a list with several bits of information. The most important being: cluster : A vector of integers\\n   (from 1:k) indicating the cluster to which each point is allocated. centers : A matrix of cluster centers.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''Interpreting the meaning of k-means clusters boils down to characterizing the clusters. A Parallel Coordinates Plot allows\n",
    "   us to see how individual data points sit across all variables. By looking at how the values for each variable compare\n",
    "   across clusters, we can get a sense of what each cluster represents.\n",
    "   The output of kmeans is a list with several bits of information. The most important being: cluster : A vector of integers\n",
    "   (from 1:k) indicating the cluster to which each point is allocated. centers : A matrix of cluster centers.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29fd601a-c804-4213-8633-c3492d4cd34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"k-Means doesn't perform well if the clusters have varying sizes, different densities, or non-spherical shapes. Has to be\\n   run for a certain amount of iteration or it would produce a suboptimal result. Computationally expensive as distance is to \\n   be calculated from each centroid to all data points.\\n   k-means has trouble clustering data where clusters are of varying sizes and density. To cluster such data, you need to\\n   generalize k-means as described in the Advantages section. Clustering outliers. Centroids can be dragged by outliers, or \\n   outliers might get their own cluster instead of being ignored.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''k-Means doesn't perform well if the clusters have varying sizes, different densities, or non-spherical shapes. Has to be\n",
    "   run for a certain amount of iteration or it would produce a suboptimal result. Computationally expensive as distance is to \n",
    "   be calculated from each centroid to all data points.\n",
    "   k-means has trouble clustering data where clusters are of varying sizes and density. To cluster such data, you need to\n",
    "   generalize k-means as described in the Advantages section. Clustering outliers. Centroids can be dragged by outliers, or \n",
    "   outliers might get their own cluster instead of being ignored.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436781a-7017-4ace-9bf7-f64c0babe1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
